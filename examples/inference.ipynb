{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///C:/openpi/openpi\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting augmax>=0.3.4 (from openpi==0.1.0)\n",
      "  Downloading augmax-0.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting beartype>=0.19.0 (from openpi==0.1.0)\n",
      "  Downloading beartype-0.20.2-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting boto3>=1.35.7 (from openpi==0.1.0)\n",
      "  Downloading boto3-1.38.19-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting dm-tree>=0.1.8 (from openpi==0.1.0)\n",
      "  Downloading dm_tree-0.1.9-cp313-cp313-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting einops>=0.8.0 (from openpi==0.1.0)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting equinox>=0.11.8 (from openpi==0.1.0)\n",
      "  Downloading equinox-0.12.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting filelock>=3.16.1 (from openpi==0.1.0)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from openpi==0.1.0)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting flax==0.10.2 (from openpi==0.1.0)\n",
      "  Downloading flax-0.10.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2024.6.0 (from fsspec[gcs]>=2024.6.0->openpi==0.1.0)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gym-aloha>=0.1.1 (from openpi==0.1.0)\n",
      "  Downloading gym_aloha-0.1.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting imageio>=2.36.1 (from openpi==0.1.0)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jax==0.5.0 (from jax[cuda12]==0.5.0->openpi==0.1.0)\n",
      "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxtyping==0.2.36 (from openpi==0.1.0)\n",
      "  Downloading jaxtyping-0.2.36-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting lerobot (from openpi==0.1.0)\n",
      "  Downloading lerobot-0.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting ml-collections==1.0.0 (from openpi==0.1.0)\n",
      "  Downloading ml_collections-1.0.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting numpy>=1.26.4 (from openpi==0.1.0)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting numpydantic>=1.6.6 (from openpi==0.1.0)\n",
      "  Downloading numpydantic-1.6.9-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting opencv-python>=4.10.0.84 (from openpi==0.1.0)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "INFO: pip is looking at multiple versions of openpi to determine which version is compatible with other requirements. This could take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.26.0 Requires-Python <3.13,>=3.9; 1.26.1 Requires-Python <3.13,>=3.9\n",
      "ERROR: Could not find a version that satisfies the requirement openpi-client (from openpi) (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for openpi-client\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jax'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model \u001b[38;5;28;01mas\u001b[39;00m _model\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolicies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m droid_policy\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'jax'"
     ]
    }
   ],
   "source": [
    "import dataclasses\n",
    "\n",
    "import jax\n",
    "\n",
    "from openpi.models import model as _model\n",
    "from openpi.policies import droid_policy\n",
    "from openpi.policies import policy_config as _policy_config\n",
    "from openpi.shared import download\n",
    "from openpi.training import config as _config\n",
    "from openpi.training import data_loader as _data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy inference\n",
    "\n",
    "The following example shows how to create a policy from a checkpoint and run inference on a dummy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = _config.get_config(\"pi0_fast_droid\")\n",
    "checkpoint_dir = download.maybe_download(\"s3://openpi-assets/checkpoints/pi0_fast_droid\")\n",
    "\n",
    "# Create a trained policy.\n",
    "policy = _policy_config.create_trained_policy(config, checkpoint_dir)\n",
    "\n",
    "# Run inference on a dummy example. This example corresponds to observations produced by the DROID runtime.\n",
    "example = droid_policy.make_droid_example()\n",
    "result = policy.infer(example)\n",
    "\n",
    "# Delete the policy to free up memory.\n",
    "del policy\n",
    "\n",
    "print(\"Actions shape:\", result[\"actions\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with a live model\n",
    "\n",
    "\n",
    "The following example shows how to create a live model from a checkpoint and compute training loss. First, we are going to demonstrate how to do it with fake data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = _config.get_config(\"pi0_aloha_sim\")\n",
    "\n",
    "checkpoint_dir = download.maybe_download(\"s3://openpi-assets/checkpoints/pi0_aloha_sim\")\n",
    "key = jax.random.key(0)\n",
    "\n",
    "# Create a model from the checkpoint.\n",
    "model = config.model.load(_model.restore_params(checkpoint_dir / \"params\"))\n",
    "\n",
    "# We can create fake observations and actions to test the model.\n",
    "obs, act = config.model.fake_obs(), config.model.fake_act()\n",
    "\n",
    "# Sample actions from the model.\n",
    "loss = model.compute_loss(key, obs, act)\n",
    "print(\"Loss shape:\", loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to create a data loader and use a real batch of training data to compute the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the batch size to reduce memory usage.\n",
    "config = dataclasses.replace(config, batch_size=2)\n",
    "\n",
    "# Load a single batch of data. This is the same data that will be used during training.\n",
    "# NOTE: In order to make this example self-contained, we are skipping the normalization step\n",
    "# since it requires the normalization statistics to be generated using `compute_norm_stats`.\n",
    "loader = _data_loader.create_data_loader(config, num_batches=1, skip_norm_stats=True)\n",
    "obs, act = next(iter(loader))\n",
    "\n",
    "# Sample actions from the model.\n",
    "loss = model.compute_loss(key, obs, act)\n",
    "\n",
    "# Delete the model to free up memory.\n",
    "del model\n",
    "\n",
    "print(\"Loss shape:\", loss.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
